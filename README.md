# Notes on Deep Learning 

In this repo I am collecting personal notes on topics in deep learning. Particularly interested in more "foundational" questions like
* Why can over-parameterizied networks generalize?
* Why are gradient descent methods able to reliably find useful minimas in a high dimensional non-convex space?
* Why do vastly different network initializations lead to similair solutions after training?
* Can we expect from a proper mathematical theory of DL that it sheds light on learning and intelligent behaviour in biological system as well?

While these notes are usually written in prose they should be understood as a loose collection of notes on research papers and thoughts as I try to understand a specific topic better.

# Notes
* [Why are neural networks able to generalize?](notes/biasvariance.md)
